{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a79a5e6",
   "metadata": {},
   "source": [
    "# GridForecast: Electricity Demand Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223a6890",
   "metadata": {},
   "source": [
    "GridForecast is an end-to-end electricity demand forecasting system built on real-time ENTSO-E operational data, combining time series analytics (ARIMA, SARIMA, Prophet, LSTM), ensemble modeling, automated monitoring, and continuous retraining to enable data-driven grid operations and energy trading decisions.\n",
    "\n",
    "From insights derived from temporal demand patterns and renewable energy variability, actionable forecasting models were developed and deployed via an interactive web application. The application provides a dashboard interface for grid operators and energy traders to visualize 24-hour demand predictions, confidence intervals, and real-time model performance to support operational planning and risk mitigation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744ebf19",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcabe42",
   "metadata": {},
   "source": [
    "The objective of the project is to predict the Electricity Demand in Germany. So we need to collect the data using API from the ENTSO-E Transparency Platform. \n",
    "ENTSO-E Transparency Platform gives access to electricity generation, transportation, and consumption data for the pan-European market. It is having the details from the countries like Austria, Belgium, Switzerland, Denmark, Germany, Spain, France, UK, Italy, Ireland, Luxembourg, the Netherlands, Norway, Portugal, and Sweden. \n",
    "\n",
    "In order to get access to API, we need to register in the website - \n",
    "[https://transparency.entsoe.eu/](https://transparency.entsoe.eu/). \n",
    "\n",
    "For complete details, kindly refer the link - \n",
    "[https://transparencyplatform.zendesk.com/hc/en-us/articles/12845911031188-How-to-get-security-token](https://transparencyplatform.zendesk.com/hc/en-us/articles/12845911031188-How-to-get-security-token). \n",
    "\n",
    "How to fetch the dataset is given in detail in the link - [https://transparencyplatform.zendesk.com/hc/en-us/articles/15696643163924-Request-Methods](https://transparencyplatform.zendesk.com/hc/en-us/articles/15696643163924-Request-Methods). \n",
    "\n",
    "\n",
    "Apart from this traditional methods, they are providing the library to fetch the data using API - [https://github.com/EnergieID/entsoe-py](https://github.com/EnergieID/entsoe-py). \n",
    "\n",
    "We will be using this library because of convenience. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a84ca4e",
   "metadata": {},
   "source": [
    "## Import libraries and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfebee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "import requests\n",
    "from entsoe import EntsoePandasClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5a0f06",
   "metadata": {},
   "source": [
    "## Loading the API Key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1d579e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "API_KEY = os.getenv('ENTSOE_API_KEY')\n",
    "\n",
    "if not API_KEY:\n",
    "    print(\"ERROR: ENTSOE_API_KEY not found\")\n",
    "\n",
    "else:\n",
    "    print(f\"API Key loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c9b789",
   "metadata": {},
   "source": [
    "# Fetching data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df164f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading batch 1: 2015-01-01 to 2015-01-31\n",
      "Creating combined dataset...\n",
      "Downloading the data\n",
      "Downloading load data (DE_50HZ) for 20150101 to 20150131\n",
      "Downloaded 2880 load records\n",
      "Downloading load forecast (DE_50HZ) for 20150101 to 20150131\n",
      "Downloaded 2880 forecast records\n",
      "Downloading generation data (DE_50HZ) for 20150101 to 20150131\n",
      "Downloaded 2880 generation records\n",
      "Downloading generation per type (DE_50HZ) for 20150101 to 20150131\n",
      "Downloaded 624 generation-per-type records\n",
      "Downloading wind/solar forecast (DE_50HZ) for 20150101 to 20150131\n",
      "Downloaded 2880 wind/solar forecast records\n",
      "Downloading day-ahead prices (DE_LU) for 20150101 to 20150131\n",
      "Day-ahead prices not available: NoMatchingDataError\n",
      "Downloading cross-border flows for 20150101 to 20150131\n",
      "  Could not download flows to FR: NoMatchingDataError\n",
      "  Could not download flows to NL: NoMatchingDataError\n",
      "  Could not download flows to BE: NoMatchingDataError\n",
      "  Could not download flows to DK_1: NoMatchingDataError\n",
      "  Downloaded cross-border flows to PL: 696 records\n",
      "  Downloaded cross-border flows to CZ: 720 records\n",
      "  Could not download flows to AT: NoMatchingDataError\n",
      "  Could not download flows to CH: NoMatchingDataError\n",
      "Downloading batch 2: 2015-01-31 to 2015-03-02\n",
      "Creating combined dataset...\n",
      "Downloading the data\n",
      "Downloading load data (DE_50HZ) for 20150131 to 20150302\n",
      "Downloaded 2880 load records\n",
      "Downloading load forecast (DE_50HZ) for 20150131 to 20150302\n",
      "Downloaded 2880 forecast records\n",
      "Downloading generation data (DE_50HZ) for 20150131 to 20150302\n",
      "Downloaded 2880 generation records\n",
      "Downloading generation per type (DE_50HZ) for 20150131 to 20150302\n",
      "Downloaded 720 generation-per-type records\n",
      "Downloading wind/solar forecast (DE_50HZ) for 20150131 to 20150302\n",
      "Downloaded 2880 wind/solar forecast records\n",
      "Downloading day-ahead prices (DE_LU) for 20150131 to 20150302\n",
      "Day-ahead prices not available: NoMatchingDataError\n",
      "Downloading cross-border flows for 20150131 to 20150302\n",
      "  Could not download flows to FR: NoMatchingDataError\n",
      "  Could not download flows to NL: NoMatchingDataError\n",
      "  Could not download flows to BE: NoMatchingDataError\n",
      "  Could not download flows to DK_1: NoMatchingDataError\n",
      "  Downloaded cross-border flows to PL: 720 records\n",
      "  Downloaded cross-border flows to CZ: 720 records\n",
      "  Could not download flows to AT: NoMatchingDataError\n",
      "  Could not download flows to CH: NoMatchingDataError\n",
      "Downloading batch 3: 2015-03-02 to 2015-04-01\n",
      "Creating combined dataset...\n",
      "Downloading the data\n",
      "Downloading load data (DE_50HZ) for 20150302 to 20150401\n",
      "Downloaded 2876 load records\n",
      "Downloading load forecast (DE_50HZ) for 20150302 to 20150401\n",
      "Downloaded 2876 forecast records\n",
      "Downloading generation data (DE_50HZ) for 20150302 to 20150401\n",
      "Downloaded 2876 generation records\n",
      "Downloading generation per type (DE_50HZ) for 20150302 to 20150401\n",
      "Downloaded 719 generation-per-type records\n",
      "Downloading wind/solar forecast (DE_50HZ) for 20150302 to 20150401\n",
      "Downloaded 2876 wind/solar forecast records\n",
      "Downloading day-ahead prices (DE_LU) for 20150302 to 20150401\n",
      "Day-ahead prices not available: NoMatchingDataError\n",
      "Downloading cross-border flows for 20150302 to 20150401\n",
      "  Could not download flows to FR: NoMatchingDataError\n",
      "  Could not download flows to NL: NoMatchingDataError\n",
      "  Could not download flows to BE: NoMatchingDataError\n",
      "  Could not download flows to DK_1: NoMatchingDataError\n",
      "  Downloaded cross-border flows to PL: 719 records\n",
      "  Downloaded cross-border flows to CZ: 719 records\n",
      "  Could not download flows to AT: NoMatchingDataError\n",
      "  Could not download flows to CH: NoMatchingDataError\n",
      "Downloading batch 4: 2015-04-01 to 2015-05-01\n",
      "Creating combined dataset...\n",
      "Downloading the data\n",
      "Downloading load data (DE_50HZ) for 20150401 to 20150501\n",
      "Downloaded 2880 load records\n",
      "Downloading load forecast (DE_50HZ) for 20150401 to 20150501\n",
      "Downloaded 2880 forecast records\n",
      "Downloading generation data (DE_50HZ) for 20150401 to 20150501\n",
      "Downloaded 2880 generation records\n",
      "Downloading generation per type (DE_50HZ) for 20150401 to 20150501\n",
      "Downloaded 720 generation-per-type records\n",
      "Downloading wind/solar forecast (DE_50HZ) for 20150401 to 20150501\n",
      "Downloaded 2880 wind/solar forecast records\n",
      "Downloading day-ahead prices (DE_LU) for 20150401 to 20150501\n",
      "Day-ahead prices not available: NoMatchingDataError\n",
      "Downloading cross-border flows for 20150401 to 20150501\n",
      "  Could not download flows to FR: NoMatchingDataError\n",
      "  Could not download flows to NL: NoMatchingDataError\n",
      "  Could not download flows to BE: NoMatchingDataError\n",
      "  Could not download flows to DK_1: NoMatchingDataError\n",
      "  Downloaded cross-border flows to PL: 720 records\n",
      "  Downloaded cross-border flows to CZ: 720 records\n",
      "  Could not download flows to AT: NoMatchingDataError\n",
      "  Could not download flows to CH: NoMatchingDataError\n",
      "Downloading batch 5: 2015-05-01 to 2015-05-31\n",
      "Creating combined dataset...\n",
      "Downloading the data\n",
      "Downloading load data (DE_50HZ) for 20150501 to 20150531\n",
      "Downloaded 2880 load records\n",
      "Downloading load forecast (DE_50HZ) for 20150501 to 20150531\n",
      "Downloaded 2880 forecast records\n",
      "Downloading generation data (DE_50HZ) for 20150501 to 20150531\n",
      "Downloaded 2880 generation records\n",
      "Downloading generation per type (DE_50HZ) for 20150501 to 20150531\n",
      "Downloaded 720 generation-per-type records\n",
      "Downloading wind/solar forecast (DE_50HZ) for 20150501 to 20150531\n",
      "Downloaded 2880 wind/solar forecast records\n",
      "Downloading day-ahead prices (DE_LU) for 20150501 to 20150531\n",
      "Day-ahead prices not available: NoMatchingDataError\n",
      "Downloading cross-border flows for 20150501 to 20150531\n",
      "  Could not download flows to FR: NoMatchingDataError\n",
      "  Could not download flows to NL: NoMatchingDataError\n",
      "  Could not download flows to BE: NoMatchingDataError\n",
      "  Could not download flows to DK_1: NoMatchingDataError\n",
      "  Downloaded cross-border flows to PL: 720 records\n",
      "  Downloaded cross-border flows to CZ: 720 records\n",
      "  Could not download flows to AT: NoMatchingDataError\n",
      "  Could not download flows to CH: NoMatchingDataError\n",
      "Downloading batch 6: 2015-05-31 to 2015-06-30\n",
      "Creating combined dataset...\n",
      "Downloading the data\n",
      "Downloading load data (DE_50HZ) for 20150531 to 20150630\n",
      "Downloaded 2880 load records\n",
      "Downloading load forecast (DE_50HZ) for 20150531 to 20150630\n",
      "Downloaded 2880 forecast records\n",
      "Downloading generation data (DE_50HZ) for 20150531 to 20150630\n",
      "Downloaded 2880 generation records\n",
      "Downloading generation per type (DE_50HZ) for 20150531 to 20150630\n",
      "Downloaded 720 generation-per-type records\n",
      "Downloading wind/solar forecast (DE_50HZ) for 20150531 to 20150630\n",
      "Downloaded 2880 wind/solar forecast records\n",
      "Downloading day-ahead prices (DE_LU) for 20150531 to 20150630\n",
      "Day-ahead prices not available: NoMatchingDataError\n",
      "Downloading cross-border flows for 20150531 to 20150630\n",
      "  Could not download flows to FR: NoMatchingDataError\n",
      "  Could not download flows to NL: NoMatchingDataError\n",
      "  Could not download flows to BE: NoMatchingDataError\n",
      "  Could not download flows to DK_1: NoMatchingDataError\n",
      "  Downloaded cross-border flows to PL: 720 records\n",
      "  Downloaded cross-border flows to CZ: 720 records\n",
      "  Could not download flows to AT: NoMatchingDataError\n",
      "  Could not download flows to CH: NoMatchingDataError\n",
      "Downloading batch 7: 2015-06-30 to 2015-07-30\n",
      "Creating combined dataset...\n",
      "Downloading the data\n",
      "Downloading load data (DE_50HZ) for 20150630 to 20150730\n",
      "Downloaded 2880 load records\n",
      "Downloading load forecast (DE_50HZ) for 20150630 to 20150730\n",
      "Downloaded 2880 forecast records\n",
      "Downloading generation data (DE_50HZ) for 20150630 to 20150730\n",
      "Downloaded 2880 generation records\n",
      "Downloading generation per type (DE_50HZ) for 20150630 to 20150730\n",
      "Downloaded 720 generation-per-type records\n",
      "Downloading wind/solar forecast (DE_50HZ) for 20150630 to 20150730\n",
      "Downloaded 2880 wind/solar forecast records\n",
      "Downloading day-ahead prices (DE_LU) for 20150630 to 20150730\n",
      "Day-ahead prices not available: NoMatchingDataError\n",
      "Downloading cross-border flows for 20150630 to 20150730\n",
      "  Could not download flows to FR: NoMatchingDataError\n",
      "  Could not download flows to NL: NoMatchingDataError\n",
      "  Could not download flows to BE: NoMatchingDataError\n",
      "  Could not download flows to DK_1: NoMatchingDataError\n",
      "  Downloaded cross-border flows to PL: 720 records\n",
      "  Downloaded cross-border flows to CZ: 720 records\n",
      "  Could not download flows to AT: NoMatchingDataError\n",
      "  Could not download flows to CH: NoMatchingDataError\n",
      "Downloading batch 8: 2015-07-30 to 2015-08-29\n",
      "Creating combined dataset...\n",
      "Downloading the data\n",
      "Downloading load data (DE_50HZ) for 20150730 to 20150829\n",
      "Downloaded 2880 load records\n",
      "Downloading load forecast (DE_50HZ) for 20150730 to 20150829\n",
      "Downloaded 2880 forecast records\n",
      "Downloading generation data (DE_50HZ) for 20150730 to 20150829\n",
      "Downloaded 2880 generation records\n",
      "Downloading generation per type (DE_50HZ) for 20150730 to 20150829\n",
      "Downloaded 720 generation-per-type records\n",
      "Downloading wind/solar forecast (DE_50HZ) for 20150730 to 20150829\n",
      "Downloaded 2880 wind/solar forecast records\n",
      "Downloading day-ahead prices (DE_LU) for 20150730 to 20150829\n",
      "Day-ahead prices not available: NoMatchingDataError\n",
      "Downloading cross-border flows for 20150730 to 20150829\n",
      "  Could not download flows to FR: NoMatchingDataError\n",
      "  Could not download flows to NL: NoMatchingDataError\n",
      "  Could not download flows to BE: NoMatchingDataError\n",
      "  Could not download flows to DK_1: NoMatchingDataError\n",
      "  Downloaded cross-border flows to PL: 720 records\n",
      "  Downloaded cross-border flows to CZ: 720 records\n",
      "  Could not download flows to AT: NoMatchingDataError\n",
      "  Could not download flows to CH: NoMatchingDataError\n",
      "Downloading batch 9: 2015-08-29 to 2015-09-28\n",
      "Creating combined dataset...\n",
      "Downloading the data\n",
      "Downloading load data (DE_50HZ) for 20150829 to 20150928\n",
      "Downloaded 2880 load records\n",
      "Downloading load forecast (DE_50HZ) for 20150829 to 20150928\n",
      "Downloaded 2880 forecast records\n",
      "Downloading generation data (DE_50HZ) for 20150829 to 20150928\n",
      "Downloaded 2880 generation records\n",
      "Downloading generation per type (DE_50HZ) for 20150829 to 20150928\n",
      "Downloaded 720 generation-per-type records\n",
      "Downloading wind/solar forecast (DE_50HZ) for 20150829 to 20150928\n",
      "Downloaded 2880 wind/solar forecast records\n",
      "Downloading day-ahead prices (DE_LU) for 20150829 to 20150928\n",
      "Day-ahead prices not available: NoMatchingDataError\n",
      "Downloading cross-border flows for 20150829 to 20150928\n",
      "  Could not download flows to FR: NoMatchingDataError\n",
      "  Could not download flows to NL: NoMatchingDataError\n",
      "  Could not download flows to BE: NoMatchingDataError\n",
      "  Could not download flows to DK_1: NoMatchingDataError\n",
      "  Downloaded cross-border flows to PL: 720 records\n",
      "  Downloaded cross-border flows to CZ: 720 records\n",
      "  Could not download flows to AT: NoMatchingDataError\n",
      "  Could not download flows to CH: NoMatchingDataError\n",
      "Downloading batch 10: 2015-09-28 to 2015-10-28\n",
      "Creating combined dataset...\n",
      "Downloading the data\n",
      "Downloading load data (DE_50HZ) for 20150928 to 20151028\n",
      "Downloaded 2884 load records\n",
      "Downloading load forecast (DE_50HZ) for 20150928 to 20151028\n",
      "Downloaded 2884 forecast records\n",
      "Downloading generation data (DE_50HZ) for 20150928 to 20151028\n",
      "Downloaded 2884 generation records\n",
      "Downloading generation per type (DE_50HZ) for 20150928 to 20151028\n",
      "Downloaded 721 generation-per-type records\n",
      "Downloading wind/solar forecast (DE_50HZ) for 20150928 to 20151028\n",
      "Downloaded 2884 wind/solar forecast records\n",
      "Downloading day-ahead prices (DE_LU) for 20150928 to 20151028\n",
      "Day-ahead prices not available: NoMatchingDataError\n",
      "Downloading cross-border flows for 20150928 to 20151028\n",
      "  Could not download flows to FR: NoMatchingDataError\n",
      "  Could not download flows to NL: NoMatchingDataError\n",
      "  Could not download flows to BE: NoMatchingDataError\n",
      "  Could not download flows to DK_1: NoMatchingDataError\n",
      "  Downloaded cross-border flows to PL: 721 records\n",
      "  Downloaded cross-border flows to CZ: 721 records\n",
      "  Could not download flows to AT: NoMatchingDataError\n",
      "  Could not download flows to CH: NoMatchingDataError\n",
      "Downloading batch 11: 2015-10-28 to 2015-11-27\n",
      "Creating combined dataset...\n",
      "Downloading the data\n",
      "Downloading load data (DE_50HZ) for 20151028 to 20151127\n",
      "Downloaded 2880 load records\n",
      "Downloading load forecast (DE_50HZ) for 20151028 to 20151127\n",
      "Downloaded 2880 forecast records\n",
      "Downloading generation data (DE_50HZ) for 20151028 to 20151127\n",
      "Downloaded 2880 generation records\n",
      "Downloading generation per type (DE_50HZ) for 20151028 to 20151127\n",
      "Downloaded 720 generation-per-type records\n",
      "Downloading wind/solar forecast (DE_50HZ) for 20151028 to 20151127\n",
      "Downloaded 2880 wind/solar forecast records\n",
      "Downloading day-ahead prices (DE_LU) for 20151028 to 20151127\n",
      "Day-ahead prices not available: NoMatchingDataError\n",
      "Downloading cross-border flows for 20151028 to 20151127\n",
      "  Could not download flows to FR: NoMatchingDataError\n",
      "  Could not download flows to NL: NoMatchingDataError\n",
      "  Could not download flows to BE: NoMatchingDataError\n",
      "  Could not download flows to DK_1: NoMatchingDataError\n",
      "  Downloaded cross-border flows to PL: 720 records\n",
      "  Downloaded cross-border flows to CZ: 720 records\n",
      "  Could not download flows to AT: NoMatchingDataError\n",
      "  Could not download flows to CH: NoMatchingDataError\n",
      "Downloading batch 12: 2015-11-27 to 2015-12-27\n",
      "Creating combined dataset...\n",
      "Downloading the data\n",
      "Downloading load data (DE_50HZ) for 20151127 to 20151227\n",
      "Downloaded 2880 load records\n",
      "Downloading load forecast (DE_50HZ) for 20151127 to 20151227\n",
      "Downloaded 2880 forecast records\n",
      "Downloading generation data (DE_50HZ) for 20151127 to 20151227\n",
      "Downloaded 2880 generation records\n",
      "Downloading generation per type (DE_50HZ) for 20151127 to 20151227\n"
     ]
    }
   ],
   "source": [
    "class GermanyElectricityDownloader:\n",
    "    def __init__(self, api_key):\n",
    "        \"\"\"\n",
    "        Initialize with ENTSO-E API key\n",
    "        \n",
    "\n",
    "        - DE_50HZ for load and generation data (has complete coverage)\n",
    "        - DE_LU for day-ahead prices (only zone with price data)\n",
    "\n",
    "        \"\"\"\n",
    "        self.client = EntsoePandasClient(api_key=api_key)\n",
    "        \n",
    "\n",
    "        self.load_gen_zone = 'DE_50HZ'      # For load and generation data\n",
    "        self.price_zone = 'DE_LU'            # For day-ahead prices\n",
    "        self.time_zone = 'Europe/Berlin'\n",
    "\n",
    "    \n",
    "    def download_load_data(self, start_date, end_date):\n",
    "        \"\"\"Download actual electricity load (consumption) in MW\"\"\"\n",
    "        print(f\"Downloading load data ({self.load_gen_zone}) for {start_date} to {end_date}\")\n",
    "        \n",
    "        try:\n",
    "            start = pd.Timestamp(start_date, tz=self.time_zone)\n",
    "            end = pd.Timestamp(end_date, tz=self.time_zone)\n",
    "            \n",
    "            load_data = self.client.query_load(self.load_gen_zone, start=start, end=end)\n",
    "            \n",
    "            print(f\"Downloaded {len(load_data)} load records\")\n",
    "            return load_data\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading load data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def download_load_forecast(self, start_date, end_date):\n",
    "        \"\"\"Download day-ahead load forecast in MW\"\"\"\n",
    "        print(f\"Downloading load forecast ({self.load_gen_zone}) for {start_date} to {end_date}\")\n",
    "        \n",
    "        try:\n",
    "            start = pd.Timestamp(start_date, tz=self.time_zone)\n",
    "            end = pd.Timestamp(end_date, tz=self.time_zone)\n",
    "            \n",
    "            forecast_data = self.client.query_load_forecast(self.load_gen_zone, start=start, end=end)\n",
    "            print(f\"Downloaded {len(forecast_data)} forecast records\")\n",
    "            return forecast_data\n",
    "        except Exception as e:\n",
    "            print(f\"Load forecast not available: {type(e).__name__}\")\n",
    "            return None\n",
    "    \n",
    "    def download_generation_data(self, start_date, end_date):\n",
    "        \"\"\"Download actual generation by source type\"\"\"\n",
    "        print(f\"Downloading generation data ({self.load_gen_zone}) for {start_date} to {end_date}\")\n",
    "        \n",
    "        try:\n",
    "            start = pd.Timestamp(start_date, tz=self.time_zone)\n",
    "            end = pd.Timestamp(end_date, tz=self.time_zone)\n",
    "            \n",
    "            gen_data = self.client.query_generation(\n",
    "                self.load_gen_zone, \n",
    "                start=start, \n",
    "                end=end, \n",
    "                psr_type=None\n",
    "            )\n",
    "\n",
    "            print(f\"Downloaded {len(gen_data)} generation records\")\n",
    "            return gen_data\n",
    "        except Exception as e:\n",
    "            print(f\"Generation data not available: {type(e).__name__}\")\n",
    "            return None\n",
    "    \n",
    "    def download_wind_solar_forecast(self, start_date, end_date):\n",
    "        \"\"\"Download wind and solar generation forecast\"\"\"\n",
    "        print(f\"Downloading wind/solar forecast ({self.load_gen_zone}) for {start_date} to {end_date}\")\n",
    "        \n",
    "        try:\n",
    "            start = pd.Timestamp(start_date, tz=self.time_zone)\n",
    "            end = pd.Timestamp(end_date, tz=self.time_zone)\n",
    "            \n",
    "            ws_forecast = self.client.query_wind_and_solar_forecast(\n",
    "                self.load_gen_zone,\n",
    "                start=start,\n",
    "                end=end\n",
    "            )\n",
    "\n",
    "            print(f\"Downloaded {len(ws_forecast)} wind/solar forecast records\")\n",
    "            return ws_forecast\n",
    "        except Exception as e:\n",
    "            print(f\"Wind/solar forecast not available: {type(e).__name__}\")\n",
    "            return None\n",
    "    \n",
    "    def download_day_ahead_prices(self, start_date, end_date):\n",
    "        \"\"\"Download day-ahead electricity prices in EUR/MWh\n",
    "        \n",
    "        \"\"\"\n",
    "        print(f\"Downloading day-ahead prices ({self.price_zone}) for {start_date} to {end_date}\")\n",
    "        \n",
    "        try:\n",
    "            start = pd.Timestamp(start_date, tz=self.time_zone)\n",
    "            end = pd.Timestamp(end_date, tz=self.time_zone)\n",
    "            \n",
    "            prices = self.client.query_day_ahead_prices(\n",
    "                self.price_zone,\n",
    "                start=start,\n",
    "                end=end\n",
    "            )\n",
    "\n",
    "            print(f\"✓ Downloaded {len(prices)} price records\")\n",
    "            return prices\n",
    "        except Exception as e:\n",
    "            print(f\"Day-ahead prices not available: {type(e).__name__}\")\n",
    "            return None\n",
    "    \n",
    "    def download_generation_per_type(self, start_date, end_date):\n",
    "        \"\"\"Download generation broken down by type (Wind, Solar, Nuclear, etc.)\"\"\"\n",
    "        print(f\"Downloading generation per type ({self.load_gen_zone}) for {start_date} to {end_date}\")\n",
    "        \n",
    "        try:\n",
    "            start = pd.Timestamp(start_date, tz=self.time_zone)\n",
    "            end = pd.Timestamp(end_date, tz=self.time_zone)\n",
    "            \n",
    "            gen_per_type = self.client.query_generation_per_plant(\n",
    "                self.load_gen_zone,\n",
    "                start=start,\n",
    "                end=end\n",
    "            )\n",
    "\n",
    "            print(f\"Downloaded {len(gen_per_type)} generation-per-type records\")\n",
    "            return gen_per_type\n",
    "        except Exception as e:\n",
    "            print(f\"Generation per type not available: {type(e).__name__}\")\n",
    "            return None\n",
    "    \n",
    "    def download_crossborder_flows(self, start_date, end_date):\n",
    "        \"\"\"Download cross-border flows to neighboring countries\"\"\"\n",
    "        print(f\"Downloading cross-border flows for {start_date} to {end_date}\")\n",
    "        \n",
    "        try:\n",
    "            start = pd.Timestamp(start_date, tz=self.time_zone)\n",
    "            end = pd.Timestamp(end_date, tz=self.time_zone)\n",
    "            \n",
    "            # Germany's neighbors \n",
    "            neighbors = ['FR', 'NL', 'BE', 'DK_1', 'PL', 'CZ', 'AT', 'CH']\n",
    "            flows_data = {}\n",
    "            \n",
    "            for neighbor in neighbors:\n",
    "                try:\n",
    "                    flows = self.client.query_crossborder_flows(\n",
    "                        self.load_gen_zone, \n",
    "                        neighbor, \n",
    "                        start=start, \n",
    "                        end=end\n",
    "                    )\n",
    "\n",
    "                    flows_data[neighbor] = flows\n",
    "                    print(f\"  Downloaded cross-border flows to {neighbor}: {len(flows)} records\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  Could not download flows to {neighbor}: {type(e).__name__}\")\n",
    "            \n",
    "            return flows_data\n",
    "        except Exception as e:\n",
    "            print(f\"Error with cross-border flows: {e}\")\n",
    "            return None\n",
    "    \n",
    "    \n",
    "    def download_all(self, start_date, end_date):\n",
    "        \"\"\"Download complete dataset for demand prediction\"\"\"\n",
    "\n",
    "        print(\"Downloading the data\")\n",
    "\n",
    "        \n",
    "        # Download core data\n",
    "        load = self.download_load_data(start_date, end_date)\n",
    "        forecast = self.download_load_forecast(start_date, end_date)\n",
    "        generation = self.download_generation_data(start_date, end_date)\n",
    "        gen_per_type = self.download_generation_per_type(start_date, end_date)\n",
    "        wind_solar = self.download_wind_solar_forecast(start_date, end_date)\n",
    "        prices = self.download_day_ahead_prices(start_date, end_date)\n",
    "        flows = self.download_crossborder_flows(start_date, end_date)\n",
    "          \n",
    "        return {\n",
    "            'load': load,\n",
    "            'load_forecast': forecast,\n",
    "            'generation': generation,\n",
    "            'generation_per_type': gen_per_type,\n",
    "            'wind_solar_forecast': wind_solar,\n",
    "            'day_ahead_prices': prices,\n",
    "            'crossborder_flows': flows\n",
    "        }\n",
    "\n",
    "\n",
    "    def create_combined_dataset(self,start_date, end_date ):\n",
    "        \"\"\"Combine ALL datasets into one CSV\"\"\"\n",
    "    \n",
    "        print(\"Creating combined dataset...\")\n",
    "\n",
    "\n",
    "        data_dict = self.download_all(start_date, end_date)\n",
    "        \n",
    "\n",
    "        load = data_dict.get('load')\n",
    "        forecast = data_dict.get('load_forecast')\n",
    "        generation = data_dict.get('generation')\n",
    "        wind_solar = data_dict.get('wind_solar_forecast')\n",
    "        prices = data_dict.get('day_ahead_prices')\n",
    "        flows = data_dict.get('crossborder_flows')\n",
    "        \n",
    "        # Check if load exists before proceeding\n",
    "        if load is None or load.empty:\n",
    "            print(\"No load data found!\")\n",
    "            return None\n",
    "\n",
    "        \n",
    "        # Start with load as base \n",
    "        combined = pd.DataFrame({'load': load.squeeze()})\n",
    "        \n",
    "        # Add other time-series \n",
    "        if forecast is not None:\n",
    "            combined['load_forecast'] = forecast.squeeze()\n",
    "        \n",
    "        if prices is not None:\n",
    "            combined['price'] = prices\n",
    "        \n",
    "        # Add generation columns \n",
    "        if generation is not None:\n",
    "            for col in generation.columns:\n",
    "                combined[f'generation_{col}'] = generation[col]\n",
    "        \n",
    "        # Add wind/solar columns\n",
    "        if wind_solar is not None:\n",
    "            for col in wind_solar.columns:\n",
    "                combined[f'forecast_{col}'] = wind_solar[col]\n",
    "        \n",
    "        # Add aggregated cross-border flows\n",
    "        if flows is not None:\n",
    "            for neighbor, flow_data in flows.items():\n",
    "                combined[f'flow_to_{neighbor}'] = flow_data.squeeze()\n",
    "\n",
    "        return combined\n",
    "    \n",
    "\n",
    "\n",
    "def main():\n",
    "    downloader = GermanyElectricityDownloader(api_key=API_KEY)\n",
    "\n",
    "    project_root = Path.cwd().parent\n",
    "    output_dir = project_root / 'artifacts/raw'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    csv_filename = 'power_consumption_germany.csv'\n",
    "    csv_file_path_str = str(output_dir / csv_filename)\n",
    "\n",
    "    if os.path.isfile(csv_file_path_str):\n",
    "        # File exists — check the last date in the CSV\n",
    "        existing_df = pd.read_csv(csv_file_path_str, index_col=0, parse_dates=True)\n",
    "        existing_df.index = pd.to_datetime(existing_df.index, utc=True).tz_convert('Europe/Berlin')\n",
    "\n",
    "        last_date = existing_df.index.max().date()\n",
    "        today = date.today()\n",
    "        yesterday = today - timedelta(days=1)\n",
    "\n",
    "        if last_date >= yesterday:\n",
    "            print(f\"CSV is already up to date (last record: {last_date}). Nothing to download.\")\n",
    "            return\n",
    "\n",
    "        # Data is stale — download missing days from day after last record to yesterday\n",
    "        fetch_start = last_date + timedelta(days=1)\n",
    "        fetch_end = yesterday + timedelta(days=1)  # ENTSO-E end is exclusive\n",
    "\n",
    "        print(f\"CSV exists but is outdated. Fetching missing data: {fetch_start} to {yesterday}\")\n",
    "\n",
    "        new_data = downloader.create_combined_dataset(\n",
    "            start_date=fetch_start.strftime('%Y%m%d'),\n",
    "            end_date=fetch_end.strftime('%Y%m%d')\n",
    "        )\n",
    "\n",
    "        if new_data is not None and not new_data.empty:\n",
    "            updated_df = pd.concat([existing_df, new_data])\n",
    "            updated_df = updated_df[~updated_df.index.duplicated(keep='last')]  # safety dedup\n",
    "            updated_df.to_csv(csv_file_path_str)\n",
    "            print(f\"Updated CSV with {len(new_data)} new rows. Total rows: {len(updated_df)}\")\n",
    "        else:\n",
    "            print(\"No new data was returned from the API.\")\n",
    "\n",
    "    else:\n",
    "        # File does not exist — do the full historical backfill\n",
    "        start = pd.Timestamp('20150101', tz='Europe/Berlin')\n",
    "        end = pd.Timestamp(date.today().strftime('%Y%m%d'), tz='Europe/Berlin')\n",
    "\n",
    "        batch = 0\n",
    "        all_data = []\n",
    "\n",
    "        while start < end:\n",
    "            batch += 1\n",
    "            batch_end = start + timedelta(days=30)\n",
    "            print(f\"Downloading batch {batch}: {start.date()} to {batch_end.date()}\")\n",
    "\n",
    "            data = downloader.create_combined_dataset(\n",
    "                start_date=start.strftime('%Y%m%d'),\n",
    "                end_date=batch_end.strftime('%Y%m%d')\n",
    "            )\n",
    "\n",
    "            if data is not None and not data.empty:\n",
    "                all_data.append(data)\n",
    "\n",
    "            start += timedelta(days=30)\n",
    "\n",
    "        if all_data:\n",
    "            final_df = pd.concat(all_data)\n",
    "            final_df = final_df[~final_df.index.duplicated(keep='last')]\n",
    "            final_df.to_csv(csv_file_path_str)\n",
    "            print(f\"\\nSuccess! Saved {len(final_df)} rows to {csv_file_path_str}\")\n",
    "        else:\n",
    "            print(\"No data was downloaded.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf64565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grid-forecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
